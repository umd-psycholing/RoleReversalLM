# -*- coding: utf-8 -*-
"""run_probing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15U1OGx7UM7XfVcXTXZGreRQJo9J59c28

# Prepare data
"""

import pandas as pd
import json
import probe

df_raw = pd.read_csv(f'/content/drive/MyDrive/LLM_role-reversal/files/df_comb.csv')

# Melt the DataFrame
melted_sentence = df_raw.melt(id_vars=["exp","item", "type", "plausibility"], value_vars=["sentence"], var_name="variable", value_name="sentence")
# Pivot the DataFrame to get implaus_sent and plaus_sent columns
pivoted_sentence = melted_sentence.pivot_table(index=["exp","item","type"], columns="plausibility", values="sentence", aggfunc='first').reset_index()
pivoted_sentence.columns = ["exp","item", "type","implaus_sent", "plaus_sent"]

# Melt the DataFrame
melted_target = df_raw.melt(id_vars=["exp","item", "type", "plausibility"], value_vars=["target"], var_name="variable", value_name="target")
# Pivot the DataFrame to get implaus_target and plaus_target columns
pivoted_target = melted_target.pivot_table(index=["exp","item","type"], columns="plausibility", values="target", aggfunc='first').reset_index()
pivoted_target.columns = ["exp","item", "type","implaus_target", "plaus_target"]

df_temp = pd.merge(pivoted_sentence,df_raw[["exp","item", "type"]],how='left',on=["exp","item", "type"]).drop_duplicates()
df = pd.merge(pivoted_target,df_temp[["exp","item", "type",'implaus_sent','plaus_sent']],how='left',on=["exp","item", "type"]).drop_duplicates()

WY_rev = df[(df['exp'] == 'WY') & (df['type'] == 'reversal')]
LE_rev = df[(df['exp'] == 'LE') & (df['type'] == 'reversal')]
KO_rev = df[(df['exp'] == 'KO') & (df['type'] == 'reversal')]
WY_sub = df[(df['exp'] == 'WY') & (df['type'] == 'substitution')]
LE_alt = df[(df['exp'] == 'LE') & (df['type'] == 'alternative')]
KO_con = df[(df['exp'] == 'KO') & (df['type'] == 'control')]
WY_LE_rev_comb = pd.concat([WY_rev, LE_rev], ignore_index=True)

"""# Run probe on verb embeddings"""

experiments = [
    (WY_rev, "WY_rev"),
    (LE_rev, "LE_rev"),
    (KO_rev, "KO_rev"),
    (WY_sub, "WY_sub"),
    (LE_alt, "LE_alt"),
    (KO_con, "KO_con"),
    (WY_LE_rev_comb, "WY_LE_rev_comb")
]

model_layers = {
    'gpt2': 12,
    'gpt2-medium': 24,
    'bert-large-uncased' : 24,
    'roberta-large' : 24
}

def main():
    for experiment, experiment_name in experiments:
      for model_name in model_layers.keys():
          model = probe.load_model(model_name)
          print(f"Loaded {model_name}")
          # bidirectional = "bert" in model_name # hacky
          probe_results = run_probe(model, model_layers[model_name], experiment, prep_fn)
          write_results(probe_results, f'/content/drive/MyDrive/LLM_role-reversal/results/probe_{experiment_name}_{model_name}.json')

def prep_fn(row):
    stimuli = [f"{row['plaus_sent']}",
               f"{row['implaus_sent']}"]
    labels = [0, 1]  # plausible is 0, implausible is 1
    verbs = [f"{row['plaus_target']}",
             f"{row['implaus_target']}"]
    return stimuli, labels, verbs

def check_stimuli_contains_verb(stimuli, verbs):
    for stimulus, verb in zip(stimuli, verbs):
        if verb not in stimulus:
            print(f"Error: Verb '{verb}' not found in stimulus '{stimulus}'")

def process_data(df, prep_fn):
    stimuli, labels, verbs = [], [], []
    for _, row in df.iterrows():
        row_stimuli, row_labels, row_verbs = prep_fn(row)
        # Check if each stimulus contains the corresponding verb
        check_stimuli_contains_verb(row_stimuli, row_verbs)
        stimuli += row_stimuli
        labels += row_labels
        verbs += row_verbs
    return stimuli, labels, verbs

def run_probe(model, layers, df, prep_fn):
    stimuli, labels, verbs = process_data(df, prep_fn)
    probing_results = {}
    for layer in range(1, layers + 1):
        embeddings = probe.extract_verb_embeddings(model, stimuli, verbs, layer)
        print("Finished with embeddings, running classifier")
        cv_results = probe.run_probing(embeddings, labels)
        print(f"Accuracy scores for 10-fold CV in layer {layer}: {cv_results}")
        probing_results[layer] = cv_results
    return probing_results

def write_results(probing_results, output_path):
    print(f"Finished probing, writing JSON of results to {output_path}")
    with open(output_path, 'w') as fp:
        json.dump(probing_results, fp)

if __name__ == "__main__":
    main()

"""# Run probe on sentence embeddings"""

# Experiment and model settings
experiments = [
    (WY_rev, "WY_rev"),
    (LE_rev, "LE_rev"),
    (KO_rev, "KO_rev"),
    (WY_sub, "WY_sub"),
    (LE_alt, "LE_alt"),
    (KO_con, "KO_con"),
    (WY_LE_rev_comb, "WY_LE_rev_comb")
]

model_layers = {
    'gpt2': 12,
    'gpt2-medium': 24,
    'bert-large-uncased': 24,
    'roberta-large': 24
}

def main():
    for experiment, experiment_name in experiments:
        for model_name in model_layers.keys():
            # Load the model and tokenizer
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            model = AutoModel.from_pretrained(model_name)
            print(f"Loaded {model_name}")
            probe_results = run_probe(model, tokenizer, model_layers[model_name], experiment, prep_fn)
            write_results(probe_results, f'/content/drive/MyDrive/LLM_role-reversal/results/probe_sent_{experiment_name}_{model_name}.json')

def prep_fn(row):
    stimuli = [f"{row['plaus_sent']}",
               f"{row['implaus_sent']}"]
    labels = [0, 1]  # plausible is 0, implausible is 1
    return stimuli, labels

def process_data(df, prep_fn):
    stimuli, labels = [], []
    for _, row in df.iterrows():
        row_stimuli, row_labels = prep_fn(row)
        stimuli += row_stimuli
        labels += row_labels
    return stimuli, labels

def run_probe(model, tokenizer, layers, df, prep_fn):
    stimuli, labels = process_data(df, prep_fn)
    probing_results = {}
    for layer in range(1, layers + 1):
        embeddings = probe.extract_sentence_embeddings(model, tokenizer, stimuli, layer)
        print("Finished with embeddings, running classifier")
        cv_results = probe.run_probing(embeddings, labels)
        print(f"Accuracy scores for 10-fold CV in layer {layer}: {cv_results}")
        probing_results[layer] = cv_results
    return probing_results

def write_results(probing_results, output_path):
    print(f"Finished probing, writing JSON of results to {output_path}")
    with open(output_path, 'w') as fp:
        json.dump(probing_results, fp)

if __name__ == "__main__":
    main()

"""# Plot verb probing results"""

import matplotlib.pyplot as plt
import pandas as pd
import json
import seaborn as sns
sns.set_theme()

model_names = ['gpt2', 'gpt2-medium', 'bert-large-uncased','roberta-large' ]
experiment_names = ["WY_rev","LE_rev","KO_rev","WY_sub","LE_alt","KO_con","WY_LE_rev_comb"]

results = {}  # Dictionary to store the results
for model_name in model_names:
  for experiment_name in experiment_names:
      file_path = f'/content/drive/MyDrive/LLM_role-reversal/results/probe_{experiment_name}_{model_name}.json'
      with open(file_path, 'r') as file:
          key = f"{experiment_name}_{model_name}"
          results[key] = json.load(file)

# Access the results using the keys, for example:
# print(results['WY_rev_gpt2'])

# Define the models and their titles
models = [
    ('gpt2', 'GPT2-small'),
    ('gpt2-medium', 'GPT2-medium'),
    ('bert-large-uncased', 'BERT-large'),
    ('roberta-large', 'RoBERTa-large')
]

# Create the figure and axes
fig, axes = plt.subplots(1, 4, figsize=(20, 6))

df1 = "WY_rev"
df2 = "WY_sub"

# Function to add the dashed line and plot the data
def plot_with_dashed_line(ax, probe_data1, probe_data2, title, experiment):
    sns.lineplot(data=probe_data1, x="Layer", y="Accuracy", label=f"{experiment} Reversal", ax=ax)
    sns.lineplot(data=probe_data2, x="Layer", y="Accuracy", label=f"{experiment} Alternative", ax=ax)
    ax.axhline(0.5, color='gray', linestyle='--')
    ax.set_title(title)
    ax.set_ylim(0, 1.1)
    ax.legend(loc='lower right')

# Plot results for each model
for ax, (model_name, title) in zip(axes, models):
    probe_data1 = pd.DataFrame(results[f'{df1}_{model_name}']).melt()
    probe_data1.columns = ['Layer', 'Accuracy']
    probe_data2 = pd.DataFrame(results[f'{df2}_{model_name}']).melt()
    probe_data2.columns = ['Layer', 'Accuracy']
    plot_with_dashed_line(ax, probe_data1, probe_data2, title, 'WY')

# Set the overall title for the figure
fig.suptitle("Verb Probe Accuracies")
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

# Create the figure and axes
fig, axes = plt.subplots(1, 4, figsize=(20, 6))

df1 = "WY_LE_rev_com"
df2 = "WY_sub"
df3 = "KO_con"

# Function to add the dashed line and plot the data
def plot_with_dashed_line(ax, probe_data1, probe_data2, title, experiment):
    sns.lineplot(data=probe_data1, x="Layer", y="Accuracy", label=f"{experiment} Reversal", ax=ax)
    sns.lineplot(data=probe_data2, x="Layer", y="Accuracy", label=f"WY Substitution", ax=ax)
    sns.lineplot(data=probe_data2, x="Layer", y="Accuracy", label=f"KO Control", ax=ax)
    ax.axhline(0.5, color='gray', linestyle='--')
    ax.set_title(title)
    ax.set_ylim(0, 1.1)
    ax.legend(loc='lower right')

# Plot results for each model
for ax, (model_name, title) in zip(axes, models):
    probe_data1 = pd.DataFrame(results[f'{df1}_{model_name}']).melt()
    probe_data1.columns = ['Layer', 'Accuracy']
    probe_data2 = pd.DataFrame(results[f'{df2}_{model_name}']).melt()
    probe_data2.columns = ['Layer', 'Accuracy']
    probe_data3 = pd.DataFrame(results[f'{df3}_{model_name}']).melt()
    probe_data3.columns = ['Layer', 'Accuracy']
    plot_with_dashed_line(ax, probe_data1, probe_data2, probe_data3, title, 'WY & LE')

# Set the overall title for the figure
fig.suptitle("Verb Probe Accuracies")
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

"""# Plot sentence probing results"""

import matplotlib.pyplot as plt
import pandas as pd
import json
import seaborn as sns
sns.set_theme()

model_names = ['gpt2', 'gpt2-medium', 'bert-large-uncased','roberta-large' ]
experiment_names = ["WY_rev","LE_rev","KO_rev","WY_sub","LE_alt","KO_con","WY_LE_rev_comb"]

results = {}  # Dictionary to store the results
for model_name in model_names:
  for experiment_name in experiment_names:
      file_path = f'/content/drive/MyDrive/LLM_role-reversal/results/probe_sent_{experiment_name}_{model_name}.json'
      with open(file_path, 'r') as file:
          key = f"{experiment_name}_{model_name}"
          results[key] = json.load(file)

# Access the results using the keys, for example:
# print(results['WY_rev_gpt2'])

# Define the models and their titles
models = [
    ('gpt2', 'GPT2-small'),
    ('gpt2-medium', 'GPT2-medium'),
    ('bert-large-uncased', 'BERT-large'),
    ('roberta-large', 'RoBERTa-large')
]

# Create the figure and axes
fig, axes = plt.subplots(1, 4, figsize=(20, 6))

df1 = "WY_rev"
df2 = "WY_sub"

# Function to add the dashed line and plot the data
def plot_with_dashed_line(ax, probe_data1, probe_data2, title, experiment):
    sns.lineplot(data=probe_data1, x="Layer", y="Accuracy", label=f"{experiment} Reversal", ax=ax)
    sns.lineplot(data=probe_data2, x="Layer", y="Accuracy", label=f"{experiment} Alternative", ax=ax)
    ax.axhline(0.5, color='gray', linestyle='--')
    ax.set_title(title)
    ax.set_ylim(0, 1.1)
    ax.legend(loc='lower right')

# Plot results for each model
for ax, (model_name, title) in zip(axes, models):
    probe_data1 = pd.DataFrame(results[f'{df1}_{model_name}']).melt()
    probe_data1.columns = ['Layer', 'Accuracy']
    probe_data2 = pd.DataFrame(results[f'{df2}_{model_name}']).melt()
    probe_data2.columns = ['Layer', 'Accuracy']
    plot_with_dashed_line(ax, probe_data1, probe_data2, title, 'WY')

# Set the overall title for the figure
fig.suptitle("Sentence Probe Accuracies")
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

# Create the figure and axes
fig, axes = plt.subplots(1, 4, figsize=(20, 6))

df1 = "WY_LE_rev_com"
df2 = "WY_sub"
df3 = "KO_con"

# Function to add the dashed line and plot the data
def plot_with_dashed_line(ax, probe_data1, probe_data2, title, experiment):
    sns.lineplot(data=probe_data1, x="Layer", y="Accuracy", label=f"{experiment} Reversal", ax=ax)
    sns.lineplot(data=probe_data2, x="Layer", y="Accuracy", label=f"WY Substitution", ax=ax)
    sns.lineplot(data=probe_data2, x="Layer", y="Accuracy", label=f"KO Control", ax=ax)
    ax.axhline(0.5, color='gray', linestyle='--')
    ax.set_title(title)
    ax.set_ylim(0, 1.1)
    ax.legend(loc='lower right')

# Plot results for each model
for ax, (model_name, title) in zip(axes, models):
    probe_data1 = pd.DataFrame(results[f'{df1}_{model_name}']).melt()
    probe_data1.columns = ['Layer', 'Accuracy']
    probe_data2 = pd.DataFrame(results[f'{df2}_{model_name}']).melt()
    probe_data2.columns = ['Layer', 'Accuracy']
    probe_data3 = pd.DataFrame(results[f'{df3}_{model_name}']).melt()
    probe_data3.columns = ['Layer', 'Accuracy']
    plot_with_dashed_line(ax, probe_data1, probe_data2, probe_data3, title, 'WY & LE')

# Set the overall title for the figure
fig.suptitle("Sentence Probe Accuracies")
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()
