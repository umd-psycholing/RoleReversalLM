# -*- coding: utf-8 -*-
"""run_probe_clean.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16tB6AzzT9_Enq_s17NBTknAbZMTq-7PG

# Prepare data
"""

import pandas as pd

df_raw = pd.read_csv(f'~/df_comb.csv')

melted_sentence = df_raw.melt(id_vars=["exp","item", "type", "plausibility"], value_vars=["sentence"], var_name="variable", value_name="sentence")
pivoted_sentence = melted_sentence.pivot_table(index=["exp","item","type"], columns="plausibility", values="sentence", aggfunc='first').reset_index()
pivoted_sentence.columns = ["exp","item", "type","implaus_sent", "plaus_sent"]

melted_target = df_raw.melt(id_vars=["exp","item", "type", "plausibility"], value_vars=["target"], var_name="variable", value_name="target")
pivoted_target = melted_target.pivot_table(index=["exp","item","type"], columns="plausibility", values="target", aggfunc='first').reset_index()
pivoted_target.columns = ["exp","item", "type","implaus_target", "plaus_target"]

df_temp = pd.merge(pivoted_sentence,df_raw[["exp","item", "type"]],how='left',on=["exp","item", "type"]).drop_duplicates()
df = pd.merge(pivoted_target,df_temp[["exp","item", "type",'implaus_sent','plaus_sent']],how='left',on=["exp","item", "type"]).drop_duplicates()

WY_rev = df[(df['exp'] == 'WY') & (df['type'] == 'reversal')]
LE_rev = df[(df['exp'] == 'LE') & (df['type'] == 'reversal')]
KO_rev = df[(df['exp'] == 'KO') & (df['type'] == 'reversal')]
WY_sub = df[(df['exp'] == 'WY') & (df['type'] == 'substitution')]
WY_con = df[(df['exp'] == 'WY') & (df['type'] == 'control')]
LE_alt = df[(df['exp'] == 'LE') & (df['type'] == 'alternative')]
KO_con = df[(df['exp'] == 'KO') & (df['type'] == 'control')]
WY_LE_rev_comb = pd.concat([WY_rev, LE_rev], ignore_index=True)
WY_KO_con_comb = pd.concat([WY_con, KO_con], ignore_index=True)

"""# Run probe on verb embeddings"""

import json
import probe

experiments = [
    (WY_rev, "WY_rev"),
    (LE_rev, "LE_rev"),
    (KO_rev, "KO_rev"),
    (WY_sub, "WY_sub"),
    (WY_con, "WY_con"),
    (LE_alt, "LE_alt"),
    (KO_con, "KO_con"),
    (WY_LE_rev_comb, "WY_LE_rev_comb"),
    (WY_KO_con_comb, "WY_KO_con_comb")
]

model_layers = {
    'gpt2': 12,
    'gpt2-medium': 24,
    'bert-large-uncased' : 24,
    'roberta-large' : 24
}

def main():
    for experiment, experiment_name in experiments:
      for model_name in model_layers.keys():
          model = probe.load_model(model_name)
          print(f"Loaded {model_name}")
          probe_results = run_probe(model, model_layers[model_name], experiment, prep_fn)
          write_results(probe_results, f'~/results/probe_{experiment_name}_{model_name}.json')

def prep_fn(row):
    stimuli = [f"{row['plaus_sent']}",
               f"{row['implaus_sent']}"]
    labels = [0, 1]  # plausible is 0, implausible is 1
    verbs = [f"{row['plaus_target']}",
             f"{row['implaus_target']}"]
    return stimuli, labels, verbs

def check_stimuli_contains_verb(stimuli, verbs):
    for stimulus, verb in zip(stimuli, verbs):
        if verb not in stimulus:
            print(f"Error: Verb '{verb}' not found in stimulus '{stimulus}'")

def process_data(df, prep_fn):
    stimuli, labels, verbs = [], [], []
    for _, row in df.iterrows():
        row_stimuli, row_labels, row_verbs = prep_fn(row)
        check_stimuli_contains_verb(row_stimuli, row_verbs)
        stimuli += row_stimuli
        labels += row_labels
        verbs += row_verbs
    return stimuli, labels, verbs

def run_probe(model, layers, df, prep_fn):
    stimuli, labels, verbs = process_data(df, prep_fn)
    probing_results = {}
    for layer in range(1, layers + 1):
        embeddings = probe.extract_verb_embeddings(model, stimuli, verbs, layer)
        print("Finished with embeddings, running classifier")
        cv_results = probe.run_probing(embeddings, labels)
        print(f"Accuracy scores for 10-fold CV in layer {layer}: {cv_results}")
        probing_results[layer] = cv_results
    return probing_results

def write_results(probing_results, output_path):
    print(f"Finished probing, writing JSON of results to {output_path}")
    with open(output_path, 'w') as fp:
        json.dump(probing_results, fp)

if __name__ == "__main__":
    main()

"""# Plot probing accuracy results"""

import matplotlib.pyplot as plt
import pandas as pd
import json
import seaborn as sns
sns.set_theme()
sns.set(font_scale=2)
sns.set_palette('colorblind')

model_names = ['gpt2', 'gpt2-medium', 'bert-large-uncased','roberta-large' ]
experiment_names = ["WY_rev","LE_rev","KO_rev","WY_sub","WY_con","LE_alt","KO_con","WY_LE_rev_comb","WY_KO_con_comb"]

results = {}
for model_name in model_names:
  for experiment_name in experiment_names:
      file_path = f'~/results/probe_{experiment_name}_{model_name}.json'
      with open(file_path, 'r') as file:
          key = f"{experiment_name}_{model_name}"
          results[key] = json.load(file)

def plot_CSLP(ax, probe_data1, probe_data2, probe_data3, title):
    sns.lineplot(data=probe_data1, x="Layer", y="Accuracy", label=f"swap-arguments", legend = False, ax=ax)
    sns.lineplot(data=probe_data2, x="Layer", y="Accuracy", label=f"replace-argument", legend = False, ax=ax)
    sns.lineplot(data=probe_data3, x="Layer", y="Accuracy", label=f"cloze", legend = False, ax=ax)
    ax.axhline(0.5, color='gray', linestyle='--')
    ax.set_title(title)
    ax.set_ylim(0, 1.1)
    ax.tick_params(axis='both',labelsize=10)
    handles, labels = ax.get_legend_handles_labels()
    fig.legend(handles, labels, loc='upper right', ncol=3, bbox_to_anchor=(0.76, 1.08), frameon=False)#

import matplotlib.pyplot as plt
import pandas as pd

fig, axes = plt.subplots(1, 4, figsize=(20, 6), sharey=True)

df1 = "WY_rev"
df2 = "WY_sub"
df3 = "WY_con"

models = [
    ('gpt2', 'GPT2-small'),
    ('gpt2-medium', 'GPT2-medium'),
    ('bert-large-uncased', 'BERT-large'),
    ('roberta-large', 'RoBERTa-large')
]

for ax, (model_name, title) in zip(axes, models):
    probe_data1 = pd.DataFrame(results[f'{df1}_{model_name}']).melt()
    probe_data1.columns = ['Layer', 'Accuracy']
    probe_data1['Layer'] = probe_data1['Layer'].astype(int)

    probe_data2 = pd.DataFrame(results[f'{df2}_{model_name}']).melt()
    probe_data2.columns = ['Layer', 'Accuracy']
    probe_data2['Layer'] = probe_data2['Layer'].astype(int)

    probe_data3 = pd.DataFrame(results[f'{df3}_{model_name}']).melt()
    probe_data3.columns = ['Layer', 'Accuracy']
    probe_data3['Layer'] = probe_data3['Layer'].astype(int)

    plot_CSLP(ax, probe_data1, probe_data2, probe_data3, title)
    ax.tick_params(axis='both', which='major', labelsize=20)
    ax.tick_params(axis='both', which='minor', labelsize=20)

    xticks = list(range(0, max(probe_data1['Layer']) + 1, 4))
    ax.set_xticks(xticks)

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()